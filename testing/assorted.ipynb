{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**comparing lists**  \n",
    "- GG > [Difference between two lists in Python](https://www.geeksforgeeks.org/python-difference-two-lists/)\n",
    "- SO > [How can I compare two lists in python and return matches](https://stackoverflow.com/questions/1388818/how-can-i-compare-two-lists-in-python-and-return-matches) (see \"this question already has answers here\")\n",
    "- docs.python.org > [Set Types -- set, frozenset](https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "# see Od2Package > Package > check_assets_filenames()\n",
    "one = [1, 2]\n",
    "two = [3, 4, 5, 6]\n",
    "diff = len(one) - len(two)\n",
    "if diff != 0:\n",
    "    print(\"difference in list lengths\")\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**an idea for working through the delimited data:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate column-by-column\n",
    "# check coll_config for column header first,\n",
    "# if no use column info from default_config\n",
    "    # either case header[0] options are:\n",
    "        # function - call function names in header[1]\n",
    "        # regex - evaluate values against regex in header [1]\n",
    "        # string - evaluate values to match exactly string in header[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*but how to call methods dynamically, without having to include opening/closing file in **each** method???*\n",
    "\n",
    "**below response/code are from Google Gemini**:  \n",
    "\n",
    "> In this approach, the CSV file is opened and read only once during the initialization of the CSVHandler class. The data is stored in the self.data attribute, which is a tuple containing the header and the data rows. Subsequent calls to the check_row method access the data from memory, eliminating the need to reopen the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class CSVHandler:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.filename, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            header = next(reader)\n",
    "            data = list(reader)\n",
    "        return header, data\n",
    "\n",
    "    def check_row(self, row_number, column_name, value):\n",
    "         header, data = self.data\n",
    "         column_index = header.index(column_name)\n",
    "         if 0 <= row_number < len(data):\n",
    "            return data[row_number][column_index] == value\n",
    "         else:\n",
    "            return False\n",
    "\n",
    "# Usage\n",
    "csv_handler = CSVHandler('my_data.csv')\n",
    "if csv_handler.check_row(0, 'Name', 'John'):\n",
    "    print(\"The value is correct\")\n",
    "else:\n",
    "    print(\"The value is incorrect or the row number is out of bounds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how to use a dictionary to dynamically select and call a method based on the column header?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works\n",
    "class MyClass: # this solution from Google Gemini\n",
    "    def method_a(self):\n",
    "        return \"Method A called\"\n",
    "\n",
    "    def method_b(self):\n",
    "        return \"Method B called\"\n",
    "\n",
    "    def method_c(self):\n",
    "        return \"Method C called\"\n",
    "\n",
    "    def select_and_call_method(self, key):\n",
    "        method_mapping = {\n",
    "            \"a\": self.method_a,\n",
    "            \"b\": self.method_b,\n",
    "            \"c\": self.method_c,\n",
    "        }\n",
    "        \n",
    "        method = method_mapping.get(key)\n",
    "        if method:\n",
    "            return method() # how does this work???\n",
    "        else:\n",
    "            return \"Invalid key\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method A called\n",
      "Method B called\n",
      "Method C called\n",
      "Invalid key\n"
     ]
    }
   ],
   "source": [
    "obj = MyClass()\n",
    "\n",
    "print(obj.select_and_call_method(\"a\"))\n",
    "print(obj.select_and_call_method(\"b\"))\n",
    "print(obj.select_and_call_method(\"c\"))\n",
    "print(obj.select_and_call_method(\"d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I'm having some regex issues**  \n",
    "\n",
    "***I may need raw to load regexes as raw strings so I'm asking about this:***  \n",
    "\n",
    "> Here's how to record a raw Python string in YAML using the PyYAML library:\n",
    "\n",
    "```Python\n",
    "import yaml\n",
    "raw_string = r\"This is a raw string with \\backslashes and newlines \\n\"\n",
    "data = {\"raw_value\": raw_string}\n",
    "with open(\"output.yaml\", \"w\") as file:\n",
    "    yaml.dump(data, file)\n",
    "```\n",
    "\n",
    "> The content of output.yaml will be:\n",
    "\n",
    "```Python\n",
    "raw_value: 'This is a raw string with \\\\backslashes and newlines \\n'\n",
    "```\n",
    "\n",
    "> YAML automatically handles the escaping of special characters within the string, preserving the raw string format. When the YAML file is loaded back into Python, the string will retain its raw format.\n",
    "\n",
    "```Python\n",
    "import yaml\n",
    "\n",
    "with open(\"output.yaml\", \"r\") as file:\n",
    "    loaded_data = yaml.safe_load(file)\n",
    "\n",
    "print(loaded_data[\"raw_value\"])\n",
    "# Expected output\n",
    "# This is a raw string with \\backslashes and newlines \\n\n",
    "```\n",
    "\n",
    "***and some more...***  \n",
    "\n",
    "> To load a raw string from a variable in Python, assign the raw string literal to the variable using the `r` prefix before the string. This ensures that backslashes and other special characters are treated literally.\n",
    "\n",
    "```Python\n",
    "raw_string_content = r\"This is a raw string with \\backslashes and \\n newlines.\"\n",
    "print(raw_string_content)\n",
    "# Output: This is a raw string with \\backslashes and \\n newlines.\n",
    "\n",
    "variable_with_path = \"C:\\\\Users\\\\example\\\\Documents\"\n",
    "raw_string_from_variable = r\"{}\".format(variable_with_path)\n",
    "print(raw_string_from_variable)\n",
    "# Output: C:\\Users\\example\\Documents\n",
    "```\n",
    "\n",
    "> It's important to remember that raw strings cannot end with an odd number of backslashes. If you need to include a trailing backslash, you can either add an extra backslash (which will be interpreted as a literal backslash) or use a regular string and escape the backslash.\n",
    "\n",
    "```Python\n",
    "invalid_raw_string = r\"This is invalid\\\" # SyntaxError: invalid syntax\n",
    "\n",
    "valid_raw_string_with_backslash = r\"This is valid\\\\\"\n",
    "print(valid_raw_string_with_backslash)\n",
    "# Output: This is valid\\\\\n",
    "\n",
    "valid_string_with_escaped_backslash = \"This is also valid\\\\\"\n",
    "print(valid_string_with_escaped_backslash)\n",
    "# Output: This is also valid\\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one potential issue - getting raw strings for a regex from yaml\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as yamlfile:\n",
    "    config = yaml.safe_load(yamlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another potential issue - using re correctly to check against regexes...\n",
    "import csv, re\n",
    "\n",
    "with open(\"/home/nebgreb/desktop/test.csv\", \"r\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for header in config:\n",
    "        if config[header][0] == 'regex':\n",
    "            # test\n",
    "            # print(config[header][1])\n",
    "            for row in reader:\n",
    "                if not re.match(config[header][1], row[header]):\n",
    "                    print(f\"correct value {row[header]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
